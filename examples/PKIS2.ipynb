{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "In this notebook, we will learn how to load the PKIS2 dataset into memory using a `DatasetProvider` object. Then we will apply some standard featurization to obtain ML-compatible representations, and use a simple model to compute some activity predictions.\n",
    "\n",
    "1. [X] Loading the data\n",
    "2. [X] Featurizing the data\n",
    "3. [X] Exporting the featurized data to PyTorch\n",
    "4. [X] Build and train the model\n",
    "5. [ ] Analyze results nicely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disable stereochemistry _warnings_ generated by `openforcefield`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") \n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the data as a DatasetProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [18:28:03] Enabling RDKit 2019.09.2 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "from kinoml.datasets.kinomescan.pkis2 import PKIS2DatasetProvider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize the PKIS2 dataset provider. Instead of a regular `ClassName()` instantiation, we need to use `.from_source()` (with convenient default arguments).\n",
    "\n",
    "__Why?__\n",
    "\n",
    "This due to the design of `BaseDatasetProvider.__init__`, which expects a list of `BaseMeasurement` objects (or subclasses of). \n",
    "\n",
    "* A `BaseMeasurement` class is normally subclassed by more specific measurements (like `BaseMeasurement`), but the design is the same. It takes:\n",
    "  * `values`: an array of numeric values (single measurements are _arrayfied_ into single-element arrays). This can be replicates of the value for statistical purposes, or under different concentrations of a reactant?\n",
    "  * `conditions`: instance of `AssayConditions`. This class provides all the properties required to reproduce the experiment (say `pH`, `temperature`, `concentration`, etc). This should be paired (somehow) to the dimensionality of `values`, but I haven't though much of that yet.\n",
    "  * `system`: instance of a `System` class or subclass. The subclasses can restrict which type of `MolecularComponent` objects are allowed (e.g. `ProteinLigandComplex` only takes a `Protein` and a `Ligand`).\n",
    "* A `System` is abstract enough to not impose any restrictions on the composition, but its subclasses can be. \n",
    "  * This is the case of the `Complex` object, which requires at least one `BaseProtein` and one `BaseLigand` objects.\n",
    "* The `MolecularComponent` class is the base object all proteins and ligands, regardless their representation (e.g. sequence vs 3D structure, smiles vs molecular graph). `MolecularComponent` is immediately subclassed by:\n",
    "  * `BaseProtein`, the abstract model which is subclassed by more concrete classes, like `AminoAcidSequence` and `ProteinStructure`.\n",
    "  * `BaseLigand`, the abstract model which is subclassed by more concrete classes, like `Ligand` (based on `openforcefield.topology.Molecule`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, all those details are not needed to start using the provider. Right now there's no lazy behavior, so it will take _a bit_ to build all sequences and ligands. In my machine, it's about 12 seconds for all 160K datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 s, sys: 392 ms, total: 20.4 s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pkis2 = PKIS2DatasetProvider.from_source()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can export a convenient dataframe with this method. Take into account this is just using the default implementation in the base class, which relies on the different `__repr__` methods and `.name` attributes of the objects involved. For prettier dataframes, one can always subclass `to_dataframe` to provide a better presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Systems</th>\n",
       "      <th>n_components</th>\n",
       "      <th>PercentageDisplacementMeasurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAK1 &amp; Clc1cccc(Cn2c(nn3c2nc(cc3=O)N2CCOCC2)C2...</td>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABL1-nonphosphorylated &amp; Clc1cccc(Cn2c(nn3c2nc...</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABL1-nonphosphorylated &amp; Clc1cccc(Cn2c(nn3c2nc...</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABL2 &amp; Clc1cccc(Cn2c(nn3c2nc(cc3=O)N2CCOCC2)C2...</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACVR1 &amp; Clc1cccc(Cn2c(nn3c2nc(cc3=O)N2CCOCC2)C...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261865</th>\n",
       "      <td>ZAP70 &amp; CCn1c(nc2c(nc(OC[C@H](N)c3ccccc3)cc12)...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261866</th>\n",
       "      <td>p38-alpha &amp; CCn1c(nc2c(nc(OC[C@H](N)c3ccccc3)c...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261867</th>\n",
       "      <td>p38-beta &amp; CCn1c(nc2c(nc(OC[C@H](N)c3ccccc3)cc...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261868</th>\n",
       "      <td>p38-delta &amp; CCn1c(nc2c(nc(OC[C@H](N)c3ccccc3)c...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261869</th>\n",
       "      <td>p38-gamma &amp; CCn1c(nc2c(nc(OC[C@H](N)c3ccccc3)c...</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261870 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Systems  n_components  \\\n",
       "0       AAK1 & Clc1cccc(Cn2c(nn3c2nc(cc3=O)N2CCOCC2)C2...             2   \n",
       "1       ABL1-nonphosphorylated & Clc1cccc(Cn2c(nn3c2nc...             2   \n",
       "2       ABL1-nonphosphorylated & Clc1cccc(Cn2c(nn3c2nc...             2   \n",
       "3       ABL2 & Clc1cccc(Cn2c(nn3c2nc(cc3=O)N2CCOCC2)C2...             2   \n",
       "4       ACVR1 & Clc1cccc(Cn2c(nn3c2nc(cc3=O)N2CCOCC2)C...             2   \n",
       "...                                                   ...           ...   \n",
       "261865  ZAP70 & CCn1c(nc2c(nc(OC[C@H](N)c3ccccc3)cc12)...             2   \n",
       "261866  p38-alpha & CCn1c(nc2c(nc(OC[C@H](N)c3ccccc3)c...             2   \n",
       "261867  p38-beta & CCn1c(nc2c(nc(OC[C@H](N)c3ccccc3)cc...             2   \n",
       "261868  p38-delta & CCn1c(nc2c(nc(OC[C@H](N)c3ccccc3)c...             2   \n",
       "261869  p38-gamma & CCn1c(nc2c(nc(OC[C@H](N)c3ccccc3)c...             2   \n",
       "\n",
       "        PercentageDisplacementMeasurement  \n",
       "0                                    14.0  \n",
       "1                                    28.0  \n",
       "2                                    20.0  \n",
       "3                                     5.0  \n",
       "4                                     0.0  \n",
       "...                                   ...  \n",
       "261865                                0.0  \n",
       "261866                                0.0  \n",
       "261867                                0.0  \n",
       "261868                                0.0  \n",
       "261869                               34.0  \n",
       "\n",
       "[261870 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pkis2.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have 260K measurements, there are roughly 250K _systems_, comprised of a reduced number of ligands and proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurements: 261870\n",
      "Systems: 257920\n",
      "Ligands: 640\n",
      "Proteins: 403\n"
     ]
    }
   ],
   "source": [
    "print(\"Measurements:\", len(pkis2.measurements))\n",
    "print(\"Systems:\", len(pkis2.systems))\n",
    "print(\"Ligands:\",len(set([s.ligand for s in pkis2.systems])))\n",
    "print(\"Proteins:\", len(set([s.protein for s in pkis2.systems])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the string representations try to be a bit informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PKIS2DatasetProvider with 261870 PercentageDisplacementMeasurement measurements and 257920 systems>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkis2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ProteinLigandComplex with 2 components (<AminoAcidSequence name=NEK5>, <Ligand name=COC(=O)c1cccc(NC(=O)NC2CCN(C2)c2ccnc(Nc3ccc(F)cc3)n2)c1>)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_random_system = next(iter(pkis2.systems))\n",
    "one_random_system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some areas do need improvement... this is how you get all the entries that have wild-type kinases (all of them in PKIS2). Maybe some Django-style queries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PKIS2DatasetProvider with 261870 PercentageDisplacementMeasurement measurements and 257920 systems>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt = [ms for ms in pkis2.measurements if ms.system.protein.metadata[\"mutations\"] is None]\n",
    "wt_provider = PKIS2DatasetProvider(measurements=wt)\n",
    "wt_provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. Featurizing the data\n",
    "\n",
    "We will be using:\n",
    "\n",
    "- MorganFingerprint n=2048 bits, r=2\n",
    "- OneHotEncoding of protein sequence\n",
    "- ... or composition of binding site\n",
    "\n",
    "An isolated featurizer takes one system and returns the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024,) 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "from kinoml.features.ligand import MorganFingerprintFeaturizer\n",
    "morgan_featurizer = MorganFingerprintFeaturizer(nbits=1024, radius=2)\n",
    "syst = morgan_featurizer.featurize(next(iter(pkis2.systems)))\n",
    "print(syst.featurizations[morgan_featurizer.name].shape, *syst.featurizations[morgan_featurizer.name][:75], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of a dataset provider, each system will store that raw data in an internal dictionary (`.featurizations`) for _each_ system. Without caching, this would take ~30 minutes, given the huge amount of duplication in the dataset. Thanks to LRU caching at the `featurizer` level, each `Ligand` is only featurized once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 279) 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ...\n"
     ]
    }
   ],
   "source": [
    "from kinoml.features.protein import OneHotEncodedSequenceFeaturizer\n",
    "sequence_featurizer = OneHotEncodedSequenceFeaturizer()\n",
    "syst = sequence_featurizer.featurize(next(iter(pkis2.systems)))\n",
    "print(syst.featurizations[sequence_featurizer.name].shape, *syst.featurizations[sequence_featurizer.name][0], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since sequence length can differ along the kinase set, we need to pad to the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ProteinLigandComplex with 2 components (<AminoAcidSequence name=PIK3C2B>, <Ligand name=COC(=O)c1cccc(NC(=O)NC2CCN(C2)c2ccnc(Nc3ccc(F)cc3)n2)c1>)> has 1634 aas\n"
     ]
    }
   ],
   "source": [
    "max_length = len(pkis2.systems[0].protein.sequence)\n",
    "best = pkis2.systems[0]\n",
    "for system in pkis2.systems[1:]:\n",
    "    this_length = len(system.protein.sequence)\n",
    "    if this_length > max_length:\n",
    "        max_length = this_length\n",
    "        best = system\n",
    "print(best, \"has\", max_length, \"aas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use annotations at UniProt to clip the useful domains. It might be too aggressive, but it's a good start.\n",
    "\n",
    "We can also try to align to Dunbrack's MSA: https://www.nature.com/articles/s41598-019-56499-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1634, 1893) 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ...\n"
     ]
    }
   ],
   "source": [
    "from kinoml.features.core import PadFeaturizer, Pipeline\n",
    "padded_featurizer = PadFeaturizer((max_length,), key=sequence_featurizer.__class__.__name__)\n",
    "padded_sequence_featurizer = Pipeline([sequence_featurizer, padded_featurizer])\n",
    "syst = padded_sequence_featurizer.featurize(next(iter(pkis2.systems)))\n",
    "print(syst.featurizations[padded_sequence_featurizer.name].shape, *syst.featurizations[padded_sequence_featurizer.name][0][:100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MorganFingerprintFeaturizer': array([0, 0, 0, ..., 0, 0, 0], dtype=uint8),\n",
       " 'OneHotEncodedSequenceFeaturizer': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'Pipeline([OneHotEncodedSequenceFeaturizer, PadFeaturizer])': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syst.featurizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we will use a simpler protein featurization, like hashed name, for easy concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56476528]\n"
     ]
    }
   ],
   "source": [
    "from kinoml.features.core import HashFeaturizer\n",
    "\n",
    "hashed_sequence_featurizer = HashFeaturizer((\"protein\", \"sequence\"))\n",
    "syst = hashed_sequence_featurizer.featurize(next(iter(pkis2.systems)))\n",
    "print(syst.featurizations[hashed_sequence_featurizer.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kinoml.features.core import Concatenated\n",
    "concat_featurizers = Concatenated([morgan_featurizer, hashed_sequence_featurizer], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurizing systems...: 100%|██████████| 257920/257920 [00:28<00:00, 8987.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.3 s, sys: 2.6 s, total: 29.9 s\n",
      "Wall time: 28.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pkis2.featurize(concat_featurizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ProteinLigandComplex with 2 components (<AminoAcidSequence name=NEK5>, <Ligand name=COC(=O)c1cccc(NC(=O)NC2CCN(C2)c2ccnc(Nc3ccc(F)cc3)n2)c1>)> ...\n",
      "   {'MorganFingerprintFeaturizer': array([0, 0, 0, ..., 0, 0, 0], dtype=uint8), 'OneHotEncodedSequenceFeaturizer': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 1., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), 'Pipeline([OneHotEncodedSequenceFeaturizer, PadFeaturizer])': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 1., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), 'HashFeaturizer': array([0.56476528]), 'Concatenated([MorganFingerprintFeaturizer, HashFeaturizer])': array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "       0.56476528]), 'last': array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "       0.56476528])} \n",
      "\n",
      "<ProteinLigandComplex with 2 components (<AminoAcidSequence name=SRPK1>, <Ligand name=Cc1ccc(cc1)S(=O)(=O)Nc1ccc(Nc2nccc(Nc3cccc4[nH]ncc34)n2)cc1>)> ...\n",
      "   {'Concatenated([MorganFingerprintFeaturizer, HashFeaturizer])': array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "       0.46359408]), 'last': array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "       0.46359408])} \n",
      "\n",
      "<ProteinLigandComplex with 2 components (<AminoAcidSequence name=NEK6>, <Ligand name=COC(=O)c1cccc(NC(=O)NC2CCN(C2)c2ccnc(Nc3ccc(F)cc3)n2)c1>)> ...\n",
      "   {'Concatenated([MorganFingerprintFeaturizer, HashFeaturizer])': array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "       0.90025318]), 'last': array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "       0.90025318])} \n",
      "\n",
      "<ProteinLigandComplex with 2 components (<AminoAcidSequence name=SRPK2>, <Ligand name=Cc1ccc(cc1)S(=O)(=O)Nc1ccc(Nc2nccc(Nc3cccc4[nH]ncc34)n2)cc1>)> ...\n",
      "   {'Concatenated([MorganFingerprintFeaturizer, HashFeaturizer])': array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "       0.13597966]), 'last': array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "       0.13597966])} \n",
      "\n",
      "<ProteinLigandComplex with 2 components (<AminoAcidSequence name=PIKFYVE>, <Ligand name=Clc1ccc(cc1)C1=C(Nc2cccc(Cl)c2)C(=O)NC1=O>)> ...\n",
      "   {'Concatenated([MorganFingerprintFeaturizer, HashFeaturizer])': array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "       0.79896036]), 'last': array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "       0.79896036])} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for system in pkis2.systems[:5]:\n",
    "    print(system, \"...\\n  \", system.featurizations, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Export to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kinoml.datasets.torch_datasets.TorchDataset at 0x7f92ad1085d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pkis2.to_pytorch()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pytorch dataset implements the `Dataset` protocol and provides two attributes: `measurements` and (featurized) `systems`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14., 28., 20., ...,  0.,  0., 34.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025,)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.systems[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Look into specifying datatypes per featurizer to use memory more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Ensuring we have an adequate observation model\n",
    "The underlying measurement type common to _all_ measurements contains an `observation_model` method that returns a dispatched callable, configurable per backend (default=pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mpct_displacement_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minhibitor_conc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-06\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_observation_model_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minhibitor_conc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# values = torch.from_numpy(values)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0minhibitor_conc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/devel/py/openkinome/kinoml/kinoml/core/measurements.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pct_displacement_model = pkis2.measurement_type.observation_model(backend=\"pytorch\")\n",
    "pct_displacement_model??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `observation_model` function expects native objects to their dataset (or numpy arrays):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Building and training the model\n",
    "\n",
    "- `DNNModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetworkRegression(nn.Module):\n",
    "    \"\"\"\n",
    "    Builds a Pytorch model (a Dense Neural Network) and a feed-forward pass\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=1024, hidden_size=100, output_size=1):\n",
    "        super(NeuralNetworkRegression, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.fully_connected_1 = nn.Linear(self.input_size, self.hidden_size) # Fully connected layer \n",
    "        self.fully_connected_out = nn.Linear(self.hidden_size, self.output_size) # Output\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the foward pass for a given input 'x'\n",
    "        \"\"\"\n",
    "        x = F.relu(self.fully_connected_1(x)) # Activations are ReLU\n",
    "        return self.fully_connected_out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Optimization loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : loss 344249.93074798584\n",
      "epoch 10 : loss 286994.50827789307\n",
      "epoch 20 : loss 264993.7321166992\n",
      "epoch 30 : loss 258397.48007202148\n",
      "epoch 40 : loss 260831.3882522583\n",
      "epoch 50 : loss 254199.86698150635\n",
      "epoch 60 : loss 252250.46099853516\n",
      "epoch 70 : loss 252102.4603881836\n",
      "epoch 80 : loss 252873.8337020874\n",
      "epoch 90 : loss 251525.9186630249\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Use DataLoader for minibatches\n",
    "loader = dataset.as_dataloader(batch_size=512)\n",
    "\n",
    "model = NeuralNetworkRegression(input_size=dataset.systems[0].shape[0])\n",
    "optimizer = torch.optim.DuD(model.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss() # Mean squared error\n",
    "\n",
    "nb_epoch = 100\n",
    "loss_timeseries = []\n",
    "for epoch in range(nb_epoch):\n",
    "    \n",
    "    cumulative_loss = 0\n",
    "    for i, (x, y) in enumerate(loader, 1):\n",
    "        # Clear gradients\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Obtain model prediction given model input\n",
    "        # x.requires_grad_()\n",
    "        delta_g = model(x)\n",
    "\n",
    "        # with observation model\n",
    "        # with torch.no_grad():\n",
    "        prediction = pct_displacement_model(delta_g)\n",
    "        loss = loss_function(prediction, y)\n",
    "\n",
    "        # Obtain loss for the predicted output\n",
    "        cumulative_loss += loss.item()\n",
    "\n",
    "        # Gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer.step()\n",
    "    loss_timeseries.append(cumulative_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch {epoch} : loss {loss_timeseries[-1]}\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss_timeseries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
